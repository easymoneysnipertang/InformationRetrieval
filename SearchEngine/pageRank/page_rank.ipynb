{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用networkx计算PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# 创建一个有向图\n",
    "G = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取mysql数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "cnx = pymysql.connect(host='localhost', user='root', password='123qwe12')\n",
    "cursor = cnx.cursor()\n",
    "cnx.select_db('IR_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_douban_url_as_node():\n",
    "    # 创建SQL查询\n",
    "    sql = \"SELECT url FROM douban\"\n",
    "    # 执行查询\n",
    "    cursor.execute(sql)\n",
    "    # 获取所有的结果\n",
    "    results = cursor.fetchall()\n",
    "    # 将结果从元组列表转换为普通列表，并添加到图中作为节点\n",
    "    for result in results:\n",
    "        G.add_node(result[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_ids_from_same_title():\n",
    "    # 创建SQL查询\n",
    "    sql = \"SELECT page_id FROM same_title\"\n",
    "    # 执行查询\n",
    "    cursor.execute(sql)\n",
    "    # 获取所有的结果\n",
    "    results = cursor.fetchall()\n",
    "    # 将结果从元组列表转换为普通列表\n",
    "    ids_same_title = [result[0] for result in results]\n",
    "    return ids_same_title\n",
    "\n",
    "def get_page_url_as_node():\n",
    "    global ids_page\n",
    "    # 创建SQL查询\n",
    "    sql = \"SELECT id,url FROM page\"\n",
    "    # 执行查询\n",
    "    cursor.execute(sql)\n",
    "    # 获取所有的结果\n",
    "    results = cursor.fetchall()\n",
    "    # 将结果从元组列表转换为普通列表\n",
    "    ids = [result[0] for result in results]\n",
    "    urls = [result[1] for result in results]\n",
    "    # 获取相同title的id\n",
    "    ids_same_title = get_ids_from_same_title()\n",
    "    print(len(ids_same_title))\n",
    "    # 去除相同title的id\n",
    "    for id,url in zip(ids,urls):\n",
    "        if id not in ids_same_title:\n",
    "            G.add_node(url)\n",
    "\n",
    "    # 从same_title中按title分组，获取每组的第一个id\n",
    "    sql = \"SELECT MIN(page_id) FROM same_title GROUP BY title\"\n",
    "    cursor.execute(sql)\n",
    "    results = cursor.fetchall()\n",
    "    ids = [result[0] for result in results]\n",
    "    print(len(ids))\n",
    "    # 找到这些id对应的url\n",
    "    for id in ids:\n",
    "        sql = \"SELECT url FROM page WHERE id = %d\" % id\n",
    "        cursor.execute(sql)\n",
    "        results = cursor.fetchall()\n",
    "        url = results[0]\n",
    "        G.add_node(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建节点 × 没必要了，创建边的时候会自动创建节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_douban_url_as_node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1435\n",
      "610\n"
     ]
    }
   ],
   "source": [
    "get_page_url_as_node()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建节点之间的边"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_douban_edges():\n",
    "    # 从数据库中获取所有的记录\n",
    "    sql = \"SELECT url, links FROM douban\"\n",
    "    cursor.execute(sql)\n",
    "    results = cursor.fetchall()\n",
    "     # 对于每一条记录\n",
    "    for url, links in results:\n",
    "        # 将links按照'\\n'解析成一个列表\n",
    "        links = links.split('\\n')\n",
    "        # 对于每一个link\n",
    "        for link in links:\n",
    "           G.add_edge(url, link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_douban_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_url_to_url_mapping():\n",
    "    # 创建一个空的映射\n",
    "    url_to_url = {}\n",
    "    # 从same_title表中按title分组，获取每组的第一个URL\n",
    "    sql = \"SELECT MIN(page_id), title FROM same_title GROUP BY title\"\n",
    "    cursor.execute(sql)\n",
    "    results = cursor.fetchall()\n",
    "    # 将每个title的所有URL映射到对应的节点\n",
    "    for page_id, title in results:\n",
    "        # 获取该title的第一个URL\n",
    "        sql = \"SELECT url FROM same_title WHERE page_id = %d\" % page_id\n",
    "        cursor.execute(sql)\n",
    "        results = cursor.fetchall()\n",
    "        target_url = results[0]\n",
    "        # 获取该title的所有URL\n",
    "        sql = \"SELECT url FROM same_title WHERE title = %s\"\n",
    "        cursor.execute(sql,(title,))\n",
    "        urls = cursor.fetchall()\n",
    "        for url in urls:\n",
    "            url_to_url[url] = target_url\n",
    "    return url_to_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拿到同title的url映射\n",
    "url_to_url = create_url_to_url_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_edges():\n",
    "    # 从数据库中获取所有的记录\n",
    "    sql = \"SELECT url, links FROM page\"\n",
    "    cursor.execute(sql)\n",
    "    results = cursor.fetchall()\n",
    "    # 对于每一条记录\n",
    "    for url, links in results:\n",
    "        # 如果URL在映射中，使用映射中的值替换URL\n",
    "        url = url_to_url.get(url, url)\n",
    "        # 将links按照'\\n'解析成一个列表\n",
    "        links = links.split('\\n')\n",
    "        # 对于每一个link\n",
    "        for link in links:\n",
    "            # 如果link在映射中，使用映射中的值替换link\n",
    "            link = url_to_url.get(link, link)\n",
    "            # 在图G中添加一条从url到link的边\n",
    "            G.add_edge(url, link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_page_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_page_rank():\n",
    "    # 使用networkx中的pagerank函数计算PR值\n",
    "    pr = nx.pagerank(G)\n",
    "    return pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更新es索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# 实例化es\n",
    "es = Elasticsearch(hosts=\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0021668640962373142\n"
     ]
    }
   ],
   "source": [
    "# 使用URL搜索文档\n",
    "res = es.search(index=\"web\", body={\"query\": {\"match\": {\"url\": 'https://www.runoob.com/'}}})\n",
    "# 查看page_id\n",
    "page_id = res['hits']['hits'][0]['_source']['pageRank']\n",
    "print(page_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch.helpers import scan\n",
    "\n",
    "def add_page_rank_to_documents(pr):\n",
    "    # 遍历web索引中的所有文档\n",
    "    for doc in scan(es, index='web'):\n",
    "        # 获取文档的URL\n",
    "        url = doc['_source']['url']\n",
    "        # 在pr字典中查询对应的PageRank值\n",
    "        page_rank = pr.get(url)\n",
    "        # 如果找到了PageRank值\n",
    "        if page_rank is not None:\n",
    "            # 更新文档，添加pageRank字段\n",
    "            es.update(index='web', id=doc['_id'], body={'doc': {'pageRank': page_rank}})\n",
    "        else :\n",
    "            # 否则，设置pageRank字段为0\n",
    "            es.update(index='web', id=doc['_id'], body={'doc': {'pageRank': 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = cal_page_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_page_rank_to_documents(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: 浪漫传奇——《贫民窟的百万富翁》, PageRank: 3.1680108217425975e-05\n",
      "Title: 需要夢想又害怕夢想, PageRank: 3.1680108217425975e-05\n",
      "Title: 贫民窟的百万富翁 Slumdog Millionaire, PageRank: 0.0004328589715619791\n",
      "Title: 唱一首歌, PageRank: 4.1406828371657615e-05\n",
      "Title: 从教育心理学的角度来扯几句, PageRank: 4.1406828371657615e-05\n",
      "Title: 嘴角漾笑, PageRank: 4.1406828371657615e-05\n",
      "Title: 傻孩子的星期六, PageRank: 4.1406828371657615e-05\n",
      "Title: 一个自私孩子的美梦, PageRank: 4.1406828371657615e-05\n",
      "Title: 蒙丹烧了学校？老师到底带孩子们去了哪里？, PageRank: 4.1406828371657615e-05\n",
      "Title: 第三次看《放牛班》，觉得蒙丹并非我们以为的坏孩子, PageRank: 4.1406828371657615e-05\n",
      "Title: 《放牛班的春天》是如何治愈你的？, PageRank: 4.1406828371657615e-05\n",
      "Title: “池塘之底”有天使, PageRank: 4.1406828371657615e-05\n",
      "Title: 有关马修老师和莫杭治的母亲, PageRank: 4.1406828371657615e-05\n",
      "Title: 放牛班的春天 Les choristes, PageRank: 0.0006807693122078392\n",
      "Title: 这个世界是异类的, PageRank: 3.8854484497569625e-05\n",
      "Title: 死亡诗社里的一段话，四首诗, PageRank: 3.8854484497569625e-05\n",
      "Title: 《死亡诗社》经典台词欣赏（转）, PageRank: 3.8854484497569625e-05\n",
      "Title: 《死亡诗社》：这一刻，我开始懂得自己, PageRank: 3.8854484497569625e-05\n",
      "Title: 作为一个大学毕业生的有感而发, PageRank: 3.8854484497569625e-05\n",
      "Title: 哦，船长，我的船长，我能不能像人一样活着？, PageRank: 3.8854484497569625e-05\n",
      "Title: 这个时候，我想起了Dead Poets Society, PageRank: 3.8854484497569625e-05\n",
      "Title: 【我最喜欢的十大外语片】之首【死亡诗社】(dead poet society), PageRank: 3.8854484497569625e-05\n",
      "Title: 死亡诗社 Dead Poets Society, PageRank: 0.0005460720041551781\n",
      "Title: SHAPE OF MY HEART, PageRank: 4.6388014021765164e-05\n",
      "Title: 坚忍的魂与隐秘的梦, PageRank: 4.6388014021765164e-05\n",
      "Title: 我以保护的方式来爱你, PageRank: 4.6388014021765164e-05\n",
      "Title: 关于杀手, PageRank: 4.6388014021765164e-05\n",
      "Title: 小萝莉与怪蜀黍阳光灿烂的日子, PageRank: 4.6388014021765164e-05\n",
      "Title: 有关Leon, PageRank: 4.6388014021765164e-05\n",
      "Title: 孤独是人类最大的杀手, PageRank: 4.6388014021765164e-05\n",
      "Title: 假如马蒂达变成洛丽塔, PageRank: 4.6388014021765164e-05\n",
      "Title: 故事来源于吕克贝松的真实经历, PageRank: 4.6388014021765164e-05\n",
      "Title: 安, PageRank: 4.6388014021765164e-05\n",
      "Title: 这个杀手不太冷 Léon, PageRank: 0.0007979093699321541\n",
      "Title: 愿我如星君如月，夜夜流光相皎洁, PageRank: 4.301140784973143e-05\n",
      "Title: 因为做不到，所以被感动, PageRank: 4.301140784973143e-05\n",
      "Title: 被 煽情, PageRank: 4.301140784973143e-05\n",
      "Title: 等你的十年，唯一的十年, PageRank: 4.301140784973143e-05\n",
      "Title: 每一个狗狗，也许都是八公, PageRank: 4.301140784973143e-05\n",
      "Title: 要有多坚强，才敢念念不忘, PageRank: 4.301140784973143e-05\n",
      "Title: 你是我一生的羁绊, PageRank: 4.301140784973143e-05\n",
      "Title: 我的一生，从与你相遇的那天便开始……, PageRank: 4.301140784973143e-05\n",
      "Title: 忠犬八公, PageRank: 4.301140784973143e-05\n",
      "Title: 忠犬八公的故事 Hachi: A Dog's Tale, PageRank: 0.0006765006879535014\n",
      "Title: McMurphy为什么要……？, PageRank: 3.382213384465603e-05\n",
      "Title: 自由何以成为悲剧, PageRank: 3.382213384465603e-05\n",
      "Title: 关于《飞越疯人院》, PageRank: 3.382213384465603e-05\n",
      "Title: 黎明之前夜有多长。, PageRank: 3.382213384465603e-05\n",
      "Title: 要飞越的其实是我们的心, PageRank: 3.382213384465603e-05\n",
      "Title: 自由与制度的悖论, PageRank: 3.382213384465603e-05\n",
      "Title: “至少我试过了”, PageRank: 3.382213384465603e-05\n",
      "Title: ～飞跃疯人院～, PageRank: 3.382213384465603e-05\n",
      "Title: 疯人院：秩序与自由之间的博弈, PageRank: 3.382213384465603e-05\n",
      "Title: 不是英雄，只是冲不过高墙的病人。, PageRank: 3.382213384465603e-05\n",
      "Title: 飞越疯人院 One Flew Over the Cuckoo's Nest, PageRank: 0.0004933837805670746\n",
      "Title: 孩子们，世界很好，你们还好吗？, PageRank: 3.944319483457732e-05\n",
      "Title: 《熔炉》始末, PageRank: 3.944319483457732e-05\n",
      "Title: 2011年，一个让整个韩国战栗的真相被揭露！【整理】, PageRank: 3.944319483457732e-05\n",
      "Title: 我今晚为什么选择了[熔炉], PageRank: 3.944319483457732e-05\n",
      "Title: 《熔炉》烘烤集体的良知, PageRank: 3.944319483457732e-05\n",
      "Title: 会车时请关掉远光灯, PageRank: 3.944319483457732e-05\n",
      "Title: 这个世界 比你想象的还要，不堪, PageRank: 3.944319483457732e-05\n",
      "Title: 伟大的反抗者、小说作者、导演与演员, PageRank: 3.944319483457732e-05\n",
      "Title: 熔炉 도가니, PageRank: 0.000564859756006801\n",
      "Title: 看完这种类型的影片后，我们必须自问的三个问题, PageRank: 3.395104530289735e-05\n",
      "Title: 这个清醒的小男孩，太让人心疼了, PageRank: 3.395104530289735e-05\n",
      "Title: 《迦百农》：“你为什么要起诉父母？因为生了我。”, PageRank: 3.395104530289735e-05\n",
      "Title: 迦百农, PageRank: 3.395104530289735e-05\n",
      "Title: 像你这样的孩子存在这世界上，让我稍微对这世界有了些期待。, PageRank: 3.395104530289735e-05\n",
      "Title: 父母不过是倒数第二块多米诺骨牌而已, PageRank: 3.395104530289735e-05\n",
      "Title: 本当是黎巴嫩《三毛流浪记》，原来是欧洲的《郭巨埋儿》, PageRank: 3.395104530289735e-05\n",
      "Title: 用尽全力的绝望, PageRank: 3.395104530289735e-05\n",
      "Title: 《何以为家》的译名很好玩, PageRank: 3.395104530289735e-05\n",
      "Title: Life is a bitch, PageRank: 3.395104530289735e-05\n",
      "Title: 何以为家 كفرناحوم, PageRank: 0.0004895648112442486\n",
      "Title: 《寄生虫》的一些细节分析, PageRank: 3.55018793798343e-05\n",
      "Title: 这虫寄生的太浅了, PageRank: 3.55018793798343e-05\n",
      "Title: 不真诚的寄生虫, PageRank: 3.55018793798343e-05\n",
      "Title: 《寄生虫》背后的韩国寄生史, PageRank: 3.55018793798343e-05\n",
      "Title: 这些人难道计划好了来体育馆大睡一觉？, PageRank: 3.55018793798343e-05\n",
      "Title: 向上的滋味, PageRank: 3.55018793798343e-05\n",
      "Title: 为什么原名《誊印》？房子才是寄生主体。, PageRank: 3.55018793798343e-05\n",
      "Title: 你爬了十层楼，可能才刚刚到达别人的地下室。, PageRank: 3.55018793798343e-05\n",
      "Title: 想想还是要参加一下影评大赛..., PageRank: 3.55018793798343e-05\n",
      "Title: 荒诞的「眩晕」, PageRank: 3.55018793798343e-05\n",
      "Title: 寄生虫 기생충, PageRank: 0.0005280578606378446\n",
      "Title: 你看起来像是个爱吃炸鸡的人, PageRank: 3.639040100531453e-05\n",
      "Title: 自《撞车》以来最逊的奥斯卡最佳影片, PageRank: 3.639040100531453e-05\n",
      "Title: DO and DO NOT List 关于真实的Donald Shirley, PageRank: 3.639040100531453e-05\n",
      "Title: 论《绿皮书》的院线中文字幕有多少错误, PageRank: 3.639040100531453e-05\n",
      "Title: 《绿皮书》有哪些有趣的设定？, PageRank: 3.639040100531453e-05\n",
      "Title: 你不知道的“绿皮书”背后的故事, PageRank: 3.639040100531453e-05\n",
      "Title: 喧嚣与孤独，构成人生的全部迷局, PageRank: 3.639040100531453e-05\n",
      "Title: 《绿皮书》和真实的事件相比，有哪些差异？, PageRank: 3.639040100531453e-05\n",
      "Title: 自以为是的和解, PageRank: 3.639040100531453e-05\n",
      "Title: 《绿皮书》拿了奥斯卡奖，但美国黑人并不喜欢？, PageRank: 3.639040100531453e-05\n",
      "Title: 绿皮书 Green Book, PageRank: 0.0005545652450775373\n",
      "Title: 重观《辛德勒名单》中80个难忘的经典影像片段（部分转载）, PageRank: 3.536778174780963e-05\n",
      "Title: 辛德勒先生，我也想在你的墓碑上放上一块石头。, PageRank: 3.536778174780963e-05\n",
      "Title: 历史上最刺眼的红, PageRank: 3.536778174780963e-05\n"
     ]
    }
   ],
   "source": [
    "## 打印PageRank值\n",
    "# 获取web索引中的前一百条文档\n",
    "res = es.search(index=\"web\", body={\"query\": {\"match_all\": {}}}, size=100)\n",
    "\n",
    "# 遍历这些文档\n",
    "for doc in res['hits']['hits']:\n",
    "    # 获取并打印文档的title和pageRank字段\n",
    "    title = doc['_source'].get('title', 'Not available')\n",
    "    page_rank = doc['_source'].get('pageRank', 'Not available')\n",
    "    print(f\"Title: {title}, PageRank: {page_rank}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试pageRank影响排序结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_bool_query(query):\n",
    "    # 执行搜索\n",
    "    response = es.search(\n",
    "        index=\"web\",\n",
    "        body={\n",
    "            \"query\": {\n",
    "                \"function_score\": {\n",
    "                    \"query\": {\n",
    "                        \"bool\": {\n",
    "                            \"must\": [\n",
    "                                {\n",
    "                                    \"multi_match\": {\n",
    "                                        \"query\": query,\n",
    "                                        \"fields\": [\"title\", \"content\"]\n",
    "                                    }\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    },\n",
    "                    \"script_score\": {\n",
    "                        \"script\": {\n",
    "                            \"source\": \"Math.log1p(doc['pageRank'].value * params.factor)\",\n",
    "                            \"params\": {\n",
    "                                \"factor\": 100000\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    \"boost_mode\": \"sum\"\n",
    "                }\n",
    "            },\n",
    "            \"explain\": True  # 添加这一行\n",
    "        }\n",
    "    )\n",
    "    # 获取搜索结果\n",
    "    hits = response[\"hits\"][\"hits\"]\n",
    "    # 格式化搜索结果\n",
    "    results = [\n",
    "        {\n",
    "            \"id\": hit[\"_id\"],\n",
    "            \"title\": hit[\"_source\"][\"title\"],\n",
    "            \"content\": hit[\"_source\"][\"content\"],\n",
    "            \"url\": hit[\"_source\"][\"url\"],\n",
    "            \"type\": hit[\"_source\"][\"type\"],\n",
    "            \"pageRank\": hit[\"_source\"][\"pageRank\"],\n",
    "            \"explanation\": hit[\"_explanation\"]  # 添加这一行\n",
    "        }\n",
    "        for hit in hits\n",
    "    ]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "肖申克的救赎 https://book.douban.com/subject/1829226/ douban\n",
      "40.591507\n",
      "肖申克的救赎 The Shawshank Redemption https://movie.douban.com/subject/1292052/ douban\n",
      "36.22301\n",
      "十年·肖申克的救赎 https://movie.douban.com/review/1000369/ douban\n",
      "35.161785\n",
      "《肖申克的救赎》到底“救赎”了什么？ https://movie.douban.com/review/10350620/ douban\n",
      "33.33816\n",
      "肖申克的救赎，读书笔记 https://book.douban.com/review/1336253/ douban\n",
      "32.47394\n",
      "《肖申克的救赎》的一些幕后花絮 https://movie.douban.com/review/1062920/ douban\n",
      "29.472248\n",
      "为何《肖申克的救赎》在IMDb和豆瓣都能排第一？ https://movie.douban.com/review/9259304/ douban\n",
      "29.19319\n",
      "汲汲而生，汲汲而死 https://book.douban.com/review/1597365/ douban\n",
      "28.38151\n",
      "《肖申克的救赎》：1994—2007，希望就是现实 https://movie.douban.com/review/1127585/ douban\n",
      "27.998638\n",
      "关于“救赎” https://movie.douban.com/review/8848890/ douban\n",
      "27.522339\n"
     ]
    }
   ],
   "source": [
    "results = deal_bool_query('肖申克的救赎')\n",
    "\n",
    "for result in results:\n",
    "    print(result['title'], result['url'], result['type'])\n",
    "    print(result['explanation']['value'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.691837003831898\n",
      "1.5995795503532988\n",
      "8.272020702549892\n",
      "5.9816541727124815\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "print(math.log1p(0.00039118477103319317*100000))\n",
    "print(math.log1p(3.9509503613941765e-05*100000))\n",
    "\n",
    "print(math.log1p(0.00039118477103319317*10000000))\n",
    "print(math.log1p(3.9509503613941765e-05*10000000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
